{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'proustr.pdf'\n",
    "loader = PyPDFLoader(input_file_path)\n",
    "texts = loader.load_and_split()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50) # need an optimal chunk size here.\n",
    "texts = text_splitter.split_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atufasheen/Downloads/projects/cg_project1/cg_venv/lib/python3.8/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "100%|██████████| 45.9M/45.9M [00:07<00:00, 6.06MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "embedding=GPT4AllEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=texts,embedding=embedding )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import GPT4All\n",
    "\n",
    "gpt4all = GPT4All(\n",
    "    model=\"/Users/atufasheen/Downloads/projects/cg_project1/local_models/mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "    max_tokens=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe main themes in these retrieved documents are related to text processing and natural language processing techniques for the French novel \"In Search of Lost Time\" by Marcel Proust. The documents contain commands and functions for tasks such as detecting days and months, stemming words and sentences, removing punctuation, converting text to lowercase, and keeping only alphanumeric characters. Additionally, there are references to specific characters and books in the novel, suggesting that these processing techniques may be used to analyze or extract information from the text.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Chain\n",
    "def format_docs(docs):\n",
    "    return docs #\"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | gpt4all | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"What are the approaches describd?\"\n",
    "docs = vectorstore.similarity_search(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='pr_detect_pro . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\npr_keep_only_alnum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\npr_normalize_punc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11', metadata={'page': 1, 'source': 'proustr.pdf'}),\n",
       " Document(page_content='pr_stem_sentences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\npr_stem_words . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\npr_unacent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13', metadata={'page': 1, 'source': 'proustr.pdf'}),\n",
       " Document(page_content='ducotedechezswann , 3\\nlaprisonniere , 4\\nlecotedeguermantes , 4\\nletempretrouve , 5\\npr_detect_days , 8\\npr_detect_months , 9\\npr_detect_pro , 9\\npr_keep_only_alnum , 10\\npr_normalize_punc , 11\\npr_stem_sentences , 11\\npr_stem_words , 12\\npr_unacent , 13\\nproust_books , 5\\nproust_char , 6\\nproust_characters , 6', metadata={'page': 14, 'source': 'proustr.pdf'}),\n",
       " Document(page_content='letempretrouve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\nproust_books . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\nproust_char . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6', metadata={'page': 1, 'source': 'proustr.pdf'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cg_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
